{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd39f103f2294bc0bb18bf43eb4add74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/9 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "168974278b35477188e644981d2cfe1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['__call__', '__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattr__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_best_guess_weight_name', '_callback_tensor_inputs', '_deprecated_kwargs', '_dict_from_json_file', '_exclude_from_cpu_offload', '_execution_device', '_fetch_state_dict', '_get_clip_prompt_embeds', '_get_init_keys', '_get_signature_keys', '_get_signature_types', '_get_t5_prompt_embeds', '_internal_dict', '_is_onnx', '_load_connected_pipes', '_lora_loadable_modules', '_optional_components', '_optionally_disable_offloading', '_upload_folder', 'check_inputs', 'clip_skip', 'components', 'config', 'config_name', 'default_sample_size', 'delete_adapters', 'device', 'disable_attention_slicing', 'disable_lora', 'disable_xformers_memory_efficient_attention', 'do_classifier_free_guidance', 'download', 'dtype', 'enable_attention_slicing', 'enable_lora', 'enable_model_cpu_offload', 'enable_sequential_cpu_offload', 'enable_xformers_memory_efficient_attention', 'encode_prompt', 'extract_init_dict', 'from_config', 'from_pipe', 'from_pretrained', 'from_single_file', 'fuse_lora', 'get_active_adapters', 'get_config_dict', 'get_list_adapters', 'guidance_scale', 'has_compatibles', 'hf_device_map', 'ignore_for_config', 'image_processor', 'interrupt', 'joint_attention_kwargs', 'load_config', 'load_lora_into_text_encoder', 'load_lora_into_transformer', 'load_lora_weights', 'lora_scale', 'lora_state_dict', 'maybe_free_model_hooks', 'model_cpu_offload_seq', 'name_or_path', 'num_fused_loras', 'num_timesteps', 'numpy_to_pil', 'pack_weights', 'patch_size', 'prepare_latents', 'progress_bar', 'push_to_hub', 'register_modules', 'register_to_config', 'remove_all_hooks', 'reset_device_map', 'save_config', 'save_lora_weights', 'save_pretrained', 'scheduler', 'set_adapters', 'set_attention_slice', 'set_lora_device', 'set_progress_bar_config', 'set_use_memory_efficient_attention_xformers', 'text_encoder', 'text_encoder_2', 'text_encoder_3', 'text_encoder_name', 'to', 'to_json_file', 'to_json_string', 'tokenizer', 'tokenizer_2', 'tokenizer_3', 'tokenizer_max_length', 'transformer', 'transformer_name', 'unfuse_lora', 'unload_lora_weights', 'vae', 'vae_scale_factor', 'write_lora_layers']\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt  # type: ignore\n",
    "# 로컬에 저장된 모델 불러오기\n",
    "save_path = \"/home/oss_1/MinsuKim/stable-diffusion-3.5-model\"\n",
    "pipe = StableDiffusion3Pipeline.from_pretrained(save_path, torch_dtype=torch.bfloat16)\n",
    "\n",
    "pipe = pipe.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# 데이터셋 클래스 정의\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_root, label_root, transform=None):\n",
    "        self.image_root = image_root\n",
    "        self.label_root = label_root\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.label_paths = []\n",
    "\n",
    "        # 이미지와 레이블 파일 경로를 일치시키는 작업\n",
    "        for image_folder in os.listdir(image_root):\n",
    "            if image_folder.endswith('.zip') or image_folder == '.ipynb_checkpoints':\n",
    "                continue\n",
    "            image_folder_path = os.path.join(image_root, image_folder)\n",
    "            label_folder_path = os.path.join(label_root, f\"TL_TEXT_{image_folder.split('_')[1]}_{image_folder.split('_')[2]}\")\n",
    "\n",
    "            for image_file in os.listdir(image_folder_path):\n",
    "                label_file = image_file.split(\".\")[0] + \".txt\"\n",
    "                self.image_paths.append(os.path.join(image_folder_path, image_file))\n",
    "                self.label_paths.append(os.path.join(label_folder_path, label_file))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        label_path = self.label_paths[idx]\n",
    "\n",
    "        # 이미지 로드 및 전처리\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # 레이블 로드\n",
    "        with open(label_path, \"r\", encoding=\"utf-8\") as file:\n",
    "            label = file.read().strip()  # 레이블 파일 내용 읽기\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# 이미지 전처리 설정 (1024x1024 크기로 조정, 정규화)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((1024, 1024)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "# 데이터셋 및 DataLoader 생성\n",
    "train_image_root = \"/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터\"\n",
    "train_label_root = \"/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터\"\n",
    "\n",
    "train_dataset = CustomDataset(train_image_root, train_label_root, transform=transform)\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Image Paths: 466984\n",
      "Number of Label Paths: 466984\n",
      "Sample Image Paths: ['/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4120040027696.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4020200016592.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4120010000416.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4020190018779.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4019880029302.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4119960008542.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4120150012485.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4120150022924.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/4020210003597.png', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/01.원천데이터/TS_03.combinationmark_P/1012611.png']\n",
      "Sample Label Paths: ['/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4120040027696.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4020200016592.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4120010000416.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4020190018779.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4019880029302.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4119960008542.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4120150012485.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4120150022924.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/4020210003597.txt', '/home/oss_1/data/240.심볼(로고) 생성 데이터/01-1.정식개방데이터/Training/02.라벨링데이터/TL_TEXT_03.combinationmark_P/1012611.txt']\n"
     ]
    }
   ],
   "source": [
    "   print(\"Number of Image Paths:\", len(train_dataset.image_paths))\n",
    "   print(\"Number of Label Paths:\", len(train_dataset.label_paths))\n",
    "   print(\"Sample Image Paths:\", train_dataset.image_paths[:10])  # 처음 10개 경로만 출력\n",
    "   print(\"Sample Label Paths:\", train_dataset.label_paths[:10])  # 처음 10개 경로만 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.image_paths)\n",
    "print(train_dataset.label_paths)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
